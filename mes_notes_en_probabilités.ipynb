{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "(Référence des formules: Bibm@th)\r\n",
    "# **Les variables aléatoires** \r\n",
    "## **1. Variables aléatoires discrètes :**\r\n",
    "Une variable aléatoire discrète est une application $X$ de $\\Omega$ (Univers, contenant toutes les possibilités) dans $E$ tel que $X(\\Omega)$ soit fini ou dénombrable.\r\n",
    "- Notons : $X(\\Omega) = \\{x_n; n \\in I\\}$ où $I$ est fini ou dénombrable.\r\n",
    "- La loi de probabilité de $X$, soit $(P_n)_{n \\; \\in \\; I}$, est noté : $P_n =P(X=x_n)$.\r\n",
    "\r\n",
    "**Note**: Un ensemble dénombrable est un ensemble en bijection avec l'ensemble des entiers $\\mathbb{N}$ (équipotent).\r\n",
    "\r\n",
    "- La probabilité $P(y|x)$ est la probabilité conditionnelle de $y$ sachant $x$ (Probabilité d'un évenement sachant qu'un autre évenement a eu lieu), et est définit comme suit :\r\n",
    "$$ P(Y = y|X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}$$\r\n",
    "où $P(X = x, Y = y)$ est l'application de la **loi conjointe** sur les variables $X$ et $Y$. \r\n",
    "- La loi conjointe entre deux variables $X$ et $Y$ est la loi qui définit toutes les probabilités du vecteur $(X, Y)$ dans un ensemble $\\mathbb{E}^2$, en d'autres termes, la probabilité de l'apparition de $X$ et $Y$ en même temps $P((X = x) \\cap (Y = y))$ (à ne pas confondre avec la probabilité conditionnelle) :\r\n",
    "$$ P_{X,Y}(I \\times J) = P(X \\in I \\; \\; et \\; \\; Y \\in J) $$  \r\n",
    "***Exemple***: Soit $E$ un évenement où on tire 2 valeurs dans l'univers $\\{-1, 1\\}^2$. $X$ est la somme des deux valeurs et $Y$ leur produit. On aura alors $X \\in \\{-2, 0, 2\\}$ et $Y \\in \\{-1, 1\\}$. Voici les valeurs possible de la loi conjointe entre $X$ et $Y$ :\r\n",
    "$$ P(X = -2, Y = -1) = 0, \\;\\;\\;\\; P(X = 0, Y = -1) = \\frac{1}{2}$$\r\n",
    "$$ P(X = 2, Y = -1) = 0, \\;\\;\\;\\; P(X = -2, Y = 1) = \\frac{1}{4}$$\r\n",
    "$$ P(X = 0, Y = 1) = 0, \\;\\;\\;\\; P(X = 2, Y = 1) = \\frac{1}{4}$$  \r\n",
    "**Note**: faites attention à l'ordre des variables dans la loi conjointe.  \r\n",
    "**Note**: Si $P(X = x, Y = y)$ est appellé loi conjointe, alors $P(X = x), P(Y = y)$ sont appellées **lois marginales**.  \r\n",
    "- Il possible de retrouver les lois marginales à partir de la loi conjointe en fixant la valeur d'une variable $X \\in \\{x_1, ..., x_p\\}$ ou $Y \\in \\{y_1, ..., y_q\\}$:\r\n",
    "$$ P(X = x_i) = \\sum_{j=1}^q P(X = x_i, Y = y_j) \\;\\; et \\;\\; P(Y = y_j) = \\sum_{i=1}^p P(X = x_i, Y = y_j)$$ \r\n",
    "- Cependant l'inverse n'est pas toujours correcte, il est possible de trouver la loi conjointe entre deux variables seulement si ces dérnières sont indépendentes, et dans ce cas là on aura :\r\n",
    "$$ P(X = x, Y = y) = P(X=x)P(Y=y)$$  \r\n",
    "Si les deux variables ne sont pas indépentes alors il faudra plus d'informations sur le rapport entre $X$ et $Y$ :\r\n",
    "$$ P(X = x, Y= y) = P(X = x)P(Y = y | X = x) \\;\\; (origine \\;\\; de \\;\\; la \\;\\; loi \\;\\; conditionnelle)$$\r\n",
    "\r\n",
    "**I. Espérence d'une variable aléatoire discrète:** notée $\\mathbb{E}[X]$, est la valeur moyenne qu'on s'attend à trouver pour la variable aléatoire $X$. La formule de l'espérence est définit comme suit :\r\n",
    "$$ \\mathbb{E}(X) = \\sum_{n \\in I} x_n P(X = x_n)$$\r\n",
    "**II. Variance d'une variable aléatoire discrète:** notée $V[X]$, la mesure de dispersion des valeurs de $X$. Elle est définit comme suit :\r\n",
    "$$ V[X] = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$$\r\n",
    "- *Démonstration* de $V[X] \\Longrightarrow$ :  \r\n",
    "$= \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2 - 2X\\mathbb{E}[X] + \\mathbb{E}[X]^2] $  \r\n",
    "$= \\mathbb{E}[X^2] - 2\\mathbb{E}[X]\\mathbb{E}[X] + \\mathbb{E}[X]^2 = \\mathbb{E}[X^2] - 2\\mathbb{E}[X]^2 + \\mathbb{E}[X]^2$  \r\n",
    "$= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$   \r\n",
    "**Note** $\\mathbb{E}[\\mathbb{E}[X]] = \\mathbb{E}[X]$  \r\n",
    "\r\n",
    "## **2. Variables aléatoires continue (Variables à densité):**\r\n",
    "Une variable aléatoire continue est une fonction $X$ de $\\Omega$ dans $\\mathbb{R}$ $(X:\\Omega \\rightarrow \\mathbb{R})$ telle qu'il existe $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ continue par morceaux et vérifiant :\r\n",
    "$$ \\forall a < b : P(X \\in [a, b]) = \\int_a^b f(x)dx$$\r\n",
    "- Si une telle fonction existe, elle est alors appellé densité de la variable aléatoire $X$. Cette fonction doit nécéssairement être positive et vérifie $\\int_{- \\infty}^{+ \\infty} f(x)dx = 1$ (l'air de la fonction $f$ correspond à une probabilité, et la somme des probabilités de tout les évenements $x_n$ dans $\\mathbb{R}$ doit être égale à 1).\r\n",
    "- On pose alors la loi suivante :\r\n",
    "$$ f(x) = \\frac{dF(x)}{dx} $$\r\n",
    "où $F(x)$ est la fonction de répartition de la variable. \r\n",
    "- Toutes variables continue est définit par une certaine fonction de répartition, et en intégrant cette dérinère on obtient la fonction de densité.\r\n",
    "\r\n",
    "**1. Espérence d'une variable aléatoire continue**: de la même manière que pour les variables discrètes, sauf qu'on utilise une intégrale étant donné la continuité de la fonction :\r\n",
    "$$ \\mathbb{E}[X] = \\int_{-\\infty}^{+\\infty} xf(x)dx $$\r\n",
    "**2. Variance d'une variable aléatoire continue** même formule : $ V[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2$\r\n",
    "\r\n",
    "## **3. Fonctions de répartition les plus connues :**\r\n",
    "### **1. Loi géométrique :**\r\n",
    "Une variable aléatoire discrète $X$ suit une loi géométrique de paramètres $p$, qu'on note $X \\sim \\mathcal{G}(p)$ si :\r\n",
    "- $X(\\Omega) = \\mathbb{N}^{*}$\r\n",
    "- $P(X = k) = p(1 - p)^{k - 1} = pq^{k - 1}$  \r\n",
    "\r\n",
    "$X$ admet alors une espérence et une variance :\r\n",
    "- $\\mathbb{E}[X] = \\frac{1}{p}$  \r\n",
    "- $V[X] = \\frac{q}{p^2} = \\frac{1 - p}{p^2}$ \r\n",
    "\r\n",
    "**Exemple**: Lancer de pièce de monnaie truquée avec les probabilités $P(pile) = p$ et $P(face) = 1 - p = q$. soit $X$ le nombre de lancers pour obtenir pile pour la première fois, $X$ suit alors une loi géométrique. Dans cet exemple, le paramètre $k$ est le nombre de lancers total.  \r\n",
    "Pour $k = 5$ (5 lancers), la probabilité d'avoir pile pour la première fois est $pqqqq = pq^4$. L'espérence dans ce cas et la probabilité moyenne d'avoir pile, avec $k = 5$ on obtient $\\mathbb{E}[X = 5] = \\frac{1}{5} = 20\\%$ de chances.\r\n",
    "\r\n",
    "### **2. Loi de Poisson :**\r\n",
    "Soit $\\lambda > 0$. Une variable aléatoir discrète $X$ suit une loi de Poisson de paramètre $\\lambda$ et noté $X \\sim \\mathcal{P}(\\lambda)$ si :\r\n",
    "- $X(\\Omega) = \\mathbb{N}$\r\n",
    "- $P(X = k) = e^{-\\lambda}\\frac{\\lambda^{k}}{k!}$\r\n",
    "\r\n",
    "$X$ admet alors une espérence et une variance :\r\n",
    "- $\\mathbb{E}[X] = \\lambda$\r\n",
    "- $V[X] = \\lambda$\r\n",
    "\r\n",
    "*Note* la loi de Poisson est la loi des phénomènes rares et des petites probabilités, généralement utiliser pour modéliser des systèmes de file d'attente. Pour plus d'informations, consulter ce [lien](https://fr.wikipedia.org/wiki/Loi_de_Poisson).\r\n",
    "\r\n",
    "### **3.Loi exponentielle :**\r\n",
    "$X$ est une variable aléatoire continue suivant la loi exponentielle de paramètre $a > 0$, note $X \\sim \\mathcal{e}(a)$ si elle est absolument continue et admet pour densité :\r\n",
    "- $f(x) = x =\\begin{cases}ae^{-ax} & si \\;\\; x > 0\\\\0 & sinon\\end{cases}$  \r\n",
    "\r\n",
    "$X$ admet une espérence et une variance :\r\n",
    "- $\\mathbb{E}[X] = \\frac{1}{a}$\r\n",
    "- $V[X] = \\frac{1}{a^2}$\r\n",
    "\r\n",
    "*Note* la loi exponentielle est la version continue de la loi géométrique; Sert souvent à modéliser la durée de vie d'une entité. $X$ dans ce cas là est une variable continue sans mémoire, et elle vérifie donc :$\\forall x, y \\geq 0$ : $P(X \\geq x+y |X \\geq y) = P(X \\geq x)$ (car on traite généralement des périodes de temps avec la loi exponentielle).  \r\n",
    "\r\n",
    "La répartition de $X$ est : $F(t) = \\begin{cases}0 & si \\;\\; t \\leq 0\\\\ 1 - e^{-at} & sinon \\end{cases}$  \r\n",
    "Je note bien $t$ et non pas $x$ car l'unité est le temps.\r\n",
    "\r\n",
    "### **4. Loi uniforme :**\r\n",
    "$X$ est une variable aléatoire continue répartit de manière uniforme sur un ensemble $[a, b]$, noté $X \\sim \\mathcal{U}(a, b)$ si elle admet comme fonction de densité :\r\n",
    "- $f(x) = \\begin{cases} \\frac{1}{b - a} & x \\in [a, b]\\\\0 & sinon \\end{cases}$  \r\n",
    "\r\n",
    "et la fonction de répartition de $X$ est alors :\r\n",
    "- $F(x) = \\begin{cases} 0 & si \\;\\; t \\leq x \\\\ \\frac{x - a}{b - a} & si \\;\\; x \\in [a, b] \\\\ 1 & sinon\\end{cases}$\r\n",
    "\r\n",
    "On donne aussi : $\\mathbb{E}[X] = \\frac{a+b}{2}$ et $V[X] = \\frac{(b-a)^2}{12}$.\r\n",
    "\r\n",
    "### **5. Loi normale (ou Gaussienne) :** (Important pour le machine learning :D)\r\n",
    "$X$ est une variable aléatoire continue dont la réparition est normale (ou Gaussienne) avec les paramètres $m$ (espérence) et $\\sigma^2$ (variance), et que l'on note $X \\sim \\mathcal{N}(m, \\sigma^2)$, si elle est continue et a pour densité :\r\n",
    "- $f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}exp(-\\frac{(x - m)^2}{2\\sigma^2})$\r\n",
    "\r\n",
    "On aura alors $\\mathbb{E}(X) = m$ et $V[X] = \\sigma^2$\r\n",
    "\r\n",
    "# **Connaissance transversales en probabilités :**\r\n",
    "## **1. Système d'événement complet :**\r\n",
    "Soit $(\\Omega, A, P)$ un espace probabiliste. Un système complet d'événement est un systèmes où tout les événements réunis forment $\\Omega$. donc :\r\n",
    "- $i \\neq j \\Longrightarrow A_i \\cup A_j = \\emptyset$;   (événemenents indépendants).\r\n",
    "- $\\bigcup_{i \\in I} A_i = \\Omega$\r\n",
    "\r\n",
    "On parle aussi de système quasi-complet quand la deuxième condition est remplacée par $\\sum_{i \\in I} P(A_i) = 1$.\r\n",
    "\r\n",
    "## **2. Expérience ou schéma de Bernoulli :**\r\n",
    "Une expérience de Bernoulli n'a que deux issues possibles, succès ($s$) ou échec ($\\overline{s}$).\r\n",
    "Le succès est définit par une probabilité $p$ et l'échec par une probabilité $q = 1 - p$.\r\n",
    "Le paramètre de l'expérience est $p$, la probabilité d'un succès.  \r\n",
    "**Exemple**: Pour un lancer de dé, la probabilité d'avoir un 6, étant le succès, est définit par $p = \\frac{1}{6}$.  \r\n",
    "$X$ est une variable aléatoire qui est définit par $X=1$ en cas de réussite et $X=0$ en cas d'échec. $X$ suit alors une loi de Bernoulli de paramètre $p$ note $X \\sim \\mathcal{B}(p)$.  \r\n",
    "$X$ admet une espérence et une variance :\r\n",
    "- $\\mathbb{E}[X] = 1 \\times p + 0 \\times (1 - p) = p$\r\n",
    "- $V[X] = p(1-p)$\r\n",
    "\r\n",
    "## **3. Loi binomiale :**\r\n",
    "On considère une expérience aléatoire qui ne possède que deux résultats : succès ($s$), échec ($\\overline{s}$). On pose :\r\n",
    "- $p = P(s)$\r\n",
    "- $q = P(\\overline{s}) = 1 - p$  \r\n",
    "\r\n",
    "On répète $n$ fois cette expérience, et on suppose que les répétitions sont indépendentes. On pose $X$ une variable aléatoire qui représente le nombre de succès au cours des $n$ répétitions, on dit alors que $X$ suit une loi binomiale de paramètre $n$ et $p$.  \r\n",
    "La probabilité d'obtenir $k$ succès au cours de $n$ répétitions est noté :\r\n",
    "$$P(X = k) = C^n_k \\times p^k(1 - p)^{n-k}$$  \r\n",
    "\r\n",
    "Où $C^n_k$, dit, $k$ parmis $n$, est le nombre de combinaisons de $k$ élements choisis parmi $n$.\r\n",
    "$C$ est le coefficient binomial et est égale au nombre de chemins conduisant à strictement $k$ succès dans l'arbre représentant le schéma de Bernoulli. Plus formellement $C$ est définit comme suit :\r\n",
    "$$C_k^n = \\frac{n!}{k!(n - k)!}$$\r\n",
    "\r\n",
    "*Note* Une expérience de Bernoulli est une loi Binomiale avec nombre de répétition $n = 1$. Une loi Binomiale est la répétition de $n$ fois le schéma de Bernoulli.\r\n",
    "\r\n",
    "#### Quelques propriété du coefficient Binomial\r\n",
    "- $C_0^n = 1$, Nombre de chemin à 0 succès dans une suite de $n$ répétitions ? un seul chemin possible.\r\n",
    "- De la même manière: $C_n^n = 1$.\r\n",
    "- $C_1^n = n$, un seul succès sur $n$ répétitions: $n$ combinaisons possibles; $n=4 \\Longrightarrow (1000, 0100, 0010, 0001)$.\r\n",
    "- Pour $0 \\leq k \\leq n$: $C^n_{n-k} = C^n_k$.\r\n",
    "- Pour $0 \\leq k \\leq n$: $C^n_k + C^n_{k+1} = C^{n+1}_{k+1}$\r\n",
    "- En utilisant les régles précédentes, on peut simplifier le calcul. **Exemple**\r\n",
    "    - $C^4_2 = C^{3 + 1}_{1 + 1} = C^3_1 + C^3_2 = 3 + C^2_1 + C^2_2 = 3 + 2 +1 = 6$\r\n",
    "\r\n",
    "## **4. Loi de Bayes :**\r\n",
    "Pour bien comprendre la loi de Bayes, il faut comprendre la notion de dépendance entre événements. Soit $A$ et $B$ deux événements :\r\n",
    "- Si $A$ et $B$ sont indépendants, alors : \r\n",
    "    - $P(A \\cap B) = P(A)P(B) = P(B)P(A) = P(B \\cap A)$  \r\n",
    "    - $P(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A)P(B)}{P(B)} = P(A)$\r\n",
    "- Si $A$ et $B$ sont dépendants, alors : \r\n",
    "    - $P(A \\cap B) = P(B)P(A|B) = P(A)P(B|A) = P(B \\cap A)$  \r\n",
    "\r\n",
    "$P(A \\cap B)$ est la probabilité de l'arrivée des événements $A$ et $B$. Dans le cas d'une dépendances entre ces dérniers, il faut alors prendre en considération l'ordre d'arrivé. Si $A$ est arrive en premier, la probabilité d'avoir $B$ lorsque $A$ est présent est définie par $P(B|A)$ ($B$ sachant $A$, et aussi noté $P_A(B)$). On aura donc $P(A \\cap B) = P(A) \\times P(B|A)$. Dans un deuxième cas où $B$ arrive en premier, on aura alors $P(B) \\times P(A|B)$.  \r\n",
    "Par inférence, on a alors :\r\n",
    "$$A \\cap B = B \\cap A \\Longleftrightarrow P(A \\cap B) = P(B \\cap A) \\Longleftrightarrow P(B)P(A|B) = P(A)P(B|A)$$  \r\n",
    "Ce qui nous donne la loi de Bayes définit par :\r\n",
    "$$ P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$  \r\n",
    "Il est à noter aussi que dans un système d'événements complet $(\\Omega, A, P)$ où toutes les probabilités $P_i$ des événements $A_i$ sont non nulles. La loi de Bayes est définit par :\r\n",
    "$$ B = B \\cap A_1 + B \\cap A_2 + ... + B \\cap A_n = \\sum_{i \\in A} B \\cap A_i$$\r\n",
    "$$ P(B) = \\sum_{n \\geq 1} P(A_n) \\times P(B | A_n)$$  \r\n",
    "Formule souvent utilisée quand le système est constitué de $A$ et $\\overline{A}$ :\r\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\\overline{A})P(\\overline{A})} $$  \r\n",
    "*Note* Attention, on se permet d'utiliser $\\overline{A}$ car on peut la déduire étant donné que le système n'est constitué que des deux événements contraires. Dans un systèmes avec plus d'événements, il faudra avoir plus d'informations sur les autres événements. De manière plus générale on notera :\r\n",
    "$$ P(A_k|B) = \\frac{P(B|A_k)P(A_k)}{P(B)} = \\frac{P(B|A_k)P(A_k)}{\\sum_{i \\geq 1}^n P(A_i)P(B |A_i)} \\;\\; avec \\;\\; k \\neq i$$  \r\n",
    "\r\n",
    "**Exemple pour avoir une meilleure idée**: Posons deux événements $A$ = \"tomber malade\" et $B$ = \"être testé positif\". La probabilité de tomber malade ($A$ arrive en premier) puis être testé positif ($B$ arrive en second) est assez élévée, soit par exemple $90\\%$, si on suppose que le test est de bonne qualité. Cependant, la probabilité d'être testé positif ($B$ arrive en premier) puis de tomber malade ($A$ arrive en second) est assez basse, il est moins probable de tomber malade en ayant déjà été testé positif.  \r\n",
    "Soit $P(A) = 30\\%$ et $P(B|A) = 90\\%$, en utilisant les formules précédentes, il est possible de calculer $P(A|B)$:\r\n",
    "- $P(B) = P(A)P(B|A) + P(\\overline{A})P(B|\\overline{A}) = 0,3 \\times 0,9 + 0,7 \\times 0,1 = 0,34$\r\n",
    "- $P(A|B) = \\frac{P(A)P(B|A)}{P(B)} = \\frac{0,3 \\times 0,9}{0,34} = 0,79$\r\n",
    "\r\n",
    "# **Processus stochastique**\r\n",
    "Un processus stochastique est une fonction du temps dont la valeur à chaque instant $t$ dépend de l'issue d'une expérience aléatoire.\r\n",
    "- Le temps peut être discret ou continu.\r\n",
    "- L'ensemble $E$ est l'ensemble des états possibles que peut prendre la variable $X^{(t)}$.  \r\n",
    "## Vecteur et matrice stochastique :\r\n",
    "- Un vecteur $\\pi = (\\pi_0, \\pi_1, \\pi_2, ..., \\pi_n)$ est stochastique seulement si la somme des composantes est égale à 1 : $\\sum_i^n \\pi_i = 1$.\r\n",
    "- Pareil pour une matrice, chaque ligne est un vecteur stochastique.  \r\n",
    "**Exemple**\r\n",
    "$$ \\pi = (\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}); \\;\\;\\; P = \r\n",
    "\\begin{bmatrix}\r\n",
    "    \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{4} & = 1\\\\ \r\n",
    "    \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} & = 1\\\\\r\n",
    "    \\frac{1}{2} & 0 & \\frac{1}{2} & = 1\\\\ \r\n",
    "\\end{bmatrix}$$\r\n",
    "\r\n",
    "## Processus sans mémoire (Processus Markovien) :\r\n",
    "Un processus Markovien est un processus ayant la propriété de Markov. L'évolution du processus ne dépend que du présent, c-à-dire qu'à un instant $t+1$, on ne dépend que de l'état à l'instant $t$ :\r\n",
    "$$ P[X_{n+1} = x_{n+1} | X_0=x_0; X_1=x_1; ...; X_n=x_n] = P[X_{n+1} = x_{x+1}|X_n=x_n]$$ \r\n",
    "\r\n",
    "# **Les chaines de Markov**\r\n",
    "## **1. Les chaines de Markov à temps discret :**\r\n",
    "$E$ est un espace d'états discrets, peut être fini ou dénombrable. ${X_n}_{n \\in E}$ est une variable aléatoire qui modélise une chaine de Markov à temps discret (CMTD) seulement si :\r\n",
    "$$ P[X_n = j | X_{n - 1} = i_{n - 1}; X_{n - 2} = i_{n-2}; ...; X_0 = i_0] = P[X_j = j|X_{n - 1} = i_{n-1}]$$  \r\n",
    "$X$ représente un processus sans mémoire.  \r\n",
    "### **Propriétés d'une CMTD :**\r\n",
    "- On pose $P_{ij}$ la probabilité de transiter vers l'état $j$ sachant qu'à l'instant $t-1$ on etait à l'état $i$.\r\n",
    "$$ P_{ij} = P[X_n = j | X_{n-1}=i]; \\;\\; \\forall n \\in \\mathbb{N}$$\r\n",
    "- On note aussi la somme des probabilités d'une transition d'un état $i$ vers $j$ est égale à 1: $ \\sum_{j \\in E} P_{ij} = 1$.\r\n",
    "- Il est possible de transiter vers le même état : $P_{ii} \\geq 0$.  \r\n",
    "**Exemple**  \r\n",
    "$E = \\{1, 2, 3, 4\\}$; $P = [P_{ij}]; i,j \\in E$\r\n",
    "$$ P = \\begin{bmatrix}\r\n",
    "    0 & P_{12} & 0 & P_{14} & = 1 \\\\\r\n",
    "    0 & 0 & 1 & 0 & =1 \\\\\r\n",
    "    P_{31} & 0 & P_{33} & 0 & =1 \\\\\r\n",
    "    1 & 0 & 0 & 0 & = 1 \r\n",
    "\\end{bmatrix}$$  \r\n",
    "*Note* Peut être représenté sous la forme d'un graphe pondéré où les poids sont les probabilités de transition.\r\n",
    "\r\n",
    "### **Distribution de l'état initial** :\r\n",
    "- L'état initial est défini par le vecteur $\\pi^{(0)} = (\\pi^{(0)}_0, \\pi^{(0)}_1, \\pi^{(0)}_2, ..., \\pi^{(0)}_n)$ où $\\pi^{(0)}_i = P[X_0 = i]$ (Probabilité que la chaine se trouve à l'état $i$ à l'instant $0$).  \r\n",
    "- Si un système est initialement à l'état $j$ alors $\\pi^{(0)}_j = 1$ et $\\pi^{(0)}_i = 0$; $\\forall i \\neq j$.\r\n",
    "\r\n",
    "## **2. Analyse d'une chaine de Markov à temps discret** :\r\n",
    "### **Régime transitoire :**\r\n",
    "Afin de déterminer le vecteur $\\pi^{(n)}$ des probabilités d'états à un instant $n$, on pose :\r\n",
    "- État du vecteur $n$ : $\\pi^{(n)} = [\\pi^{(n)}_j]_{j \\in E} = [\\pi^{(n)}_1, \\pi^{(n)}_2, \\pi^{(n)}_3, ..., \\pi^{(n)}_j]$.\r\n",
    "- Les valeurs de transition dépendent de la matrice de transition $P$ :\r\n",
    "$$\\pi^{(n)}_j = P[X_n = j] = \\sum_{i \\in E} P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i] \\;\\; Loi \\;\\; de \\;\\; Bayes$$\r\n",
    "$$\\pi^{(n)}_j = \\sum_{i \\in E} \\pi^{(n-1)}_j \\times P_{ij}$$  \r\n",
    "Par récursion jusqu'à $0$, on obtient :\r\n",
    "$$\\pi^{(n)}_j = \\pi^{(n-1)} \\times P = \\pi^{(0)}P^n$$  \r\n",
    "**Explication**  \r\n",
    "$P[X_n = j]$ est la probabilité d'être à l'état $n$ à l'instant $j$ et est noté $\\pi{(n)}_j$. Pour obtenir cette probabilité d'être à l'état $n$, il faut sommer toutes les probabilités de transition vers cette état en démarrant de l'état précédent $i$ (Il faut considérer tout les chemins possibles). Plus formellement cela donne $P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i]$ pour un seul chemin, en sommant le tout on obtient $\\Longleftrightarrow \\sum_{i \\in E} P[X_{n - 1} = i] \\times P[X_n = j | X_{n - 1} = i]$.  \r\n",
    "Pour encore mieux comprendre, il faut savoir que $P[X_n = i]$ est simplement la probabilité d'être à l'état $i$ qu'on note $\\pi$. quant à $P[X_n = i| X_{n - 1} = j]$, c'est la probabilité de **transiter** de l'état $j$ vers $i$ et qu'on note $P$ (C'est une matrice).  \r\n",
    "Quant à la récursion jusu'à $0$, voici un déroulement pour mieux comprendre :\r\n",
    "- $\\pi^{(1)} = \\pi^{(0)} \\times P$\r\n",
    "- $\\pi^{(2)} = \\pi^{(1)} \\times P = \\pi^{(0)} \\times P^2$\r\n",
    "- $\\pi^{(3)} = \\pi^{(2)} \\times P = \\pi^{(0)} \\times P^3$\r\n",
    "- ...\r\n",
    "- $\\pi^{(n)} = \\pi^{(0)} \\times P^n$ *Appellé formule de probabilités totales*\r\n",
    "\r\n",
    "### **Évolution globale du processus $X_n$ ($m$ étapes) :** ... à suivre"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('deeplearning': conda)"
  },
  "interpreter": {
   "hash": "101b61497117ea3f18d4e0f8cf93eb2d64c16663f47aa00fa1289b89b66d7e41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}